{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Embedding, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from numpy import array\n",
    "from pickle import dump, load\n",
    "from random import randint\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nShe Looks So Perfect Lyrics\\n</td>\n",
       "      <td>http://www.metrolyrics.com/she-looks-so-perfec...</td>\n",
       "      <td>Hey, hey, hey, hey, Hey, hey, hey, hey, Hey, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nShape of You Lyrics\\n</td>\n",
       "      <td>http://www.metrolyrics.com/shape-of-you-lyrics...</td>\n",
       "      <td>The club isn't the best place to find a lover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nPerfect Lyrics\\n</td>\n",
       "      <td>http://www.metrolyrics.com/perfect-lyrics-ed-s...</td>\n",
       "      <td>I found a love for me, Darling, just dive rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nPhotograph Lyrics\\n</td>\n",
       "      <td>http://www.metrolyrics.com/photograph-lyrics-e...</td>\n",
       "      <td>Loving can hurt, Loving can hurt sometimes, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nThinking Out Loud Lyrics\\n</td>\n",
       "      <td>http://www.metrolyrics.com/thinking-out-loud-l...</td>\n",
       "      <td>When your legs don't work like they used to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song_Name  \\\n",
       "0  \\nShe Looks So Perfect Lyrics\\n   \n",
       "1          \\nShape of You Lyrics\\n   \n",
       "2               \\nPerfect Lyrics\\n   \n",
       "3            \\nPhotograph Lyrics\\n   \n",
       "4     \\nThinking Out Loud Lyrics\\n   \n",
       "\n",
       "                                                Link  \\\n",
       "0  http://www.metrolyrics.com/she-looks-so-perfec...   \n",
       "1  http://www.metrolyrics.com/shape-of-you-lyrics...   \n",
       "2  http://www.metrolyrics.com/perfect-lyrics-ed-s...   \n",
       "3  http://www.metrolyrics.com/photograph-lyrics-e...   \n",
       "4  http://www.metrolyrics.com/thinking-out-loud-l...   \n",
       "\n",
       "                                              Lyrics  \n",
       "0   Hey, hey, hey, hey, Hey, hey, hey, hey, Hey, ...  \n",
       "1   The club isn't the best place to find a lover...  \n",
       "2   I found a love for me, Darling, just dive rig...  \n",
       "3   Loving can hurt, Loving can hurt sometimes, B...  \n",
       "4   When your legs don't work like they used to b...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ed_sheeran.csv', names=[\"Song_Name\", \"Link\", \"Lyrics\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[['Song_Name', 'Link']]\n",
    "y = data['Lyrics']\n",
    "# X_train, X_test, data_train, data_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "split_at = int(0.8 * len(y))\n",
    "y_train = y[: split_at]\n",
    "y_test = y[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences_file(data, out_filename, n=50):\n",
    "    \"\"\"\n",
    "    Function to generate a file of sequences containing n words in each line\n",
    "    \n",
    "    # Arguments\n",
    "        data: Input dataframe containing only lyrics\n",
    "        n: Number of words in a sequence. Default is 50\n",
    "        out_filename: Path including filename to be saved (in '.txt')\n",
    "        \n",
    "    # Returns\n",
    "        Total number of sequences in the generated file\n",
    "    \"\"\"\n",
    "    def get_lines(df):\n",
    "        corpus = []\n",
    "        for index, row in df.iteritems():\n",
    "            row = str(row).lower()\n",
    "            for words in row.split(','):\n",
    "                new_words = re.findall(r\"\\b[a-z']+\\b\", unidecode(words))\n",
    "                corpus = corpus + new_words\n",
    "        return corpus\n",
    "\n",
    "    all_lines = get_lines(data)\n",
    "    \n",
    "    # organize into sequences of tokens\n",
    "    SEQ_LENGTH = n + 1\n",
    "    sequences = list()\n",
    "    for i in range(SEQ_LENGTH, len(all_lines)):\n",
    "        # select sequence of tokens\n",
    "        seq = all_lines[i - SEQ_LENGTH: i]\n",
    "        # convert into a line\n",
    "        line = ' '.join(seq)\n",
    "        # store\n",
    "        sequences.append(line)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "        \n",
    "    # save tokens to file, one dialog per line\n",
    "    def save_doc(lines, filename):\n",
    "        data = '\\n'.join(lines)\n",
    "        file = open(filename, 'w')\n",
    "        file.write(data)\n",
    "        file.close()\n",
    "\n",
    "    # save sequences to file\n",
    "    save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 50628\n",
      "Total Sequences: 11701\n",
      "Total Sequences: 62380\n"
     ]
    }
   ],
   "source": [
    "sequences_file(y_train, 'train_seq.txt', 50)\n",
    "sequences_file(y_test, 'test_seq.txt', 50)\n",
    "sequences_file(data['Lyrics'], 'full_seq.txt', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(model_type, in_filename, embedding='word', bsize=256, epoc=25, lrate=0.001):\n",
    "    \"\"\"\n",
    "    Function to generate a language model\n",
    "    \n",
    "    # Arguments\n",
    "        model_type: Choose a model from ['rnn', 'bi_rnn', 'multi_rnn']\n",
    "        in_filename: Path of input file containing sequences to be trianed on\n",
    "        embedding: Choose a word embedding from ['word', 'glove', 'one_hot', 'word2vec']\n",
    "        bsize: Batch size to fit the model on\n",
    "        epoc: Number of epochs to be trained on\n",
    "        lrate: Learning rate to be used\n",
    "        \n",
    "    # Returns\n",
    "        Saves the model & tokenizer files and returns the filenames\n",
    "    \"\"\"\n",
    "    # load doc into memory\n",
    "    def load_doc(filename):\n",
    "        # open the file as read only\n",
    "        file = open(filename, 'r')\n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        # close the file\n",
    "        file.close()\n",
    "        return text\n",
    "\n",
    "    # load\n",
    "    doc = load_doc(in_filename)\n",
    "    lines = doc.split('\\n')\n",
    "\n",
    "    # integer encode sequences of words\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    # vocabulary size\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # separate into input and output\n",
    "    sequences = array(sequences)\n",
    "    a = int(0.8 * len(sequences))\n",
    "    X, y = sequences[:a, :-1], sequences[:a, -1]\n",
    "    y = to_categorical(y, num_classes=vocab_size)\n",
    "    seq_length = X.shape[1]\n",
    "    \n",
    "    if embedding == 'glove':\n",
    "        embeddings_index = {}\n",
    "        f = open(os.path.join('/home/affine/Deep Learning/glove.6B/', 'glove.6B.100d.txt')) # change path & embeddings dimension accordingly\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        \n",
    "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100)) # embedding_dim = 100 - using glove 100d\n",
    "        for word, i in tokenizer.word_index.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                \n",
    "    if embedding == 'word2vec':\n",
    "        def word2vec_embed(df=data['Lyrics']):\n",
    "            # creating a corpus for word2vec\n",
    "            corpus = []\n",
    "            for index, row in df.iteritems():\n",
    "                new_words_1=[]\n",
    "                row = str(row).lower()\n",
    "                for words in row.split(','):\n",
    "                    new_words = re.findall(r\"\\b[a-z']+\\b\", unidecode(words))\n",
    "                    new_words_1 = new_words_1 + new_words\n",
    "                corpus.append(new_words_1)\n",
    "            \n",
    "            # defining word2vec model\n",
    "            model = Word2Vec(corpus, min_count=1, size=100, window=5)\n",
    "            words = list(model.wv.vocab)\n",
    "\n",
    "            # creating word2vec embedding matrix\n",
    "            embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "            for word, i in tokenizer.word_index.items():\n",
    "                embedding_vector = model.wv.__getitem__(word)\n",
    "                if embedding_vector is not None:\n",
    "                    # words not found in embedding index will be all-zeros.\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "            return embedding_matrix\n",
    "\n",
    "        embedding_matrix = word2vec_embed()\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # adding embedding layer accordingly\n",
    "    if embedding == 'glove' or embedding == 'word2vec':\n",
    "        model.add(Embedding(vocab_size, 100, input_length=seq_length, weights=[embedding_matrix], trainable=True))\n",
    "    else:\n",
    "        model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    # adding rnn layers accordingly\n",
    "    if model_type == 'rnn':\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(LSTM(100))\n",
    "    elif model_type == 'bi_rnn':\n",
    "        # LSTM Layer: We will initialise a bidirectional LSTM layer\n",
    "        model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "        # LSTM Layer: We will initialise another bidirectional LSTM layer\n",
    "        model.add(Bidirectional(LSTM(100)))\n",
    "    elif model_type == 'multi_rnn':\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(LSTM(100))\n",
    "    # adding dense layers           \n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    print(model.summary())\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lrate), metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(X, y, batch_size=bsize, epochs=epoc)\n",
    "\n",
    "    # save the model to file\n",
    "    model.save(model_type + embedding + str(bsize) + str(epoc) + str(int(lrate * 10000)) + '.h5')\n",
    "    # save the tokenizer\n",
    "    dump(tokenizer, open(model_type + embedding + str(bsize) + str(epoc) + str(int(lrate * 10000)) + '_tokenizer.pkl', 'wb'))\n",
    "    return model_type + embedding + str(bsize) + str(epoc) + str(int(lrate * 10000)) + '.h5', model_type + embedding + str(bsize) + str(epoc) + str(int(lrate * 10000)) + '_tokenizer.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(in_filename, model_file, tokenizer_pickle_file):\n",
    "    \"\"\"\n",
    "    Function to generate a language model\n",
    "    \n",
    "    # Arguments\n",
    "        in_filename: Path of input file containing sequences\n",
    "        model_file: Path of trained model name to be used for prediction\n",
    "        tokenizer_pickle_file: Path of tokenizer pickle file to be used\n",
    "        \n",
    "    # Returns\n",
    "        Prints the input sequence, sequence to be followed & predicted sequence and\n",
    "        returns Bleu scores considering 1, 2, 3, 4 - grams\n",
    "    \"\"\"\n",
    "    # load doc into memory\n",
    "    def load_doc(filename):\n",
    "        # open the file as read only\n",
    "        file = open(filename, 'r')\n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        # close the file\n",
    "        file.close()\n",
    "        return text\n",
    "\n",
    "    # generate a sequence from a language model\n",
    "    def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "        result = list()\n",
    "        in_text = seed_text\n",
    "        # generate a fixed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "            # truncate sequences to a fixed length\n",
    "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "            # predict probabilities for each word\n",
    "            yhat = model.predict_classes(encoded, verbose=0)\n",
    "            # map predicted word index to word\n",
    "            out_word = ''\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            # append to input\n",
    "            in_text += ' ' + out_word\n",
    "            result.append(out_word)\n",
    "        return ' '.join(result)\n",
    "\n",
    "    # load cleaned text sequences\n",
    "    doc = load_doc(in_filename)\n",
    "    lines = doc.split('\\n')\n",
    "    seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "    # load the model\n",
    "    model = load_model(model_file)\n",
    "\n",
    "    # load the tokenizer\n",
    "    tokenizer = load(open(tokenizer_pickle_file, 'rb'))\n",
    "\n",
    "    # select a seed text\n",
    "#     seed_num = randint(0,len(lines))\n",
    "    seed_num = 1000\n",
    "    seed_text = lines[seed_num]\n",
    "    print('Input text -----')\n",
    "    print(seed_text + '\\n')\n",
    "    \n",
    "    # actual text\n",
    "    actual = []\n",
    "    act_text = lines[seed_num + 51]\n",
    "    print('Actual text -----')\n",
    "    print(act_text + '\\n')\n",
    "    actual.append([act_text.split()])\n",
    "    \n",
    "    # generate new text\n",
    "    predicted = []\n",
    "    generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "    print('Predicted text -----')\n",
    "    print(generated)\n",
    "    predicted.append(generated.split())\n",
    "    \n",
    "#     return ('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    return corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)), corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)), corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)), corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 863,144\n",
      "Trainable params: 863,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 72s 1ms/step - loss: 6.1869 - accuracy: 0.0370\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 75s 2ms/step - loss: 5.9647 - accuracy: 0.0406\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 81s 2ms/step - loss: 5.7609 - accuracy: 0.0461\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 80s 2ms/step - loss: 5.3893 - accuracy: 0.0702\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 73s 1ms/step - loss: 5.0750 - accuracy: 0.0884\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 71s 1ms/step - loss: 4.8170 - accuracy: 0.1133\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.5663 - accuracy: 0.1383\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 71s 1ms/step - loss: 4.3235 - accuracy: 0.1657\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.0965 - accuracy: 0.1924\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.8837 - accuracy: 0.2179\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 3.6828 - accuracy: 0.2447\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.4986 - accuracy: 0.2718\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 3.3204 - accuracy: 0.2983\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 3.1513 - accuracy: 0.3270\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.9947 - accuracy: 0.3541\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.8467 - accuracy: 0.3803\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.7077 - accuracy: 0.4058\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.5781 - accuracy: 0.4302\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.4473 - accuracy: 0.4541\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.3307 - accuracy: 0.4796\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.2131 - accuracy: 0.5030\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.1104 - accuracy: 0.5264\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 2.0066 - accuracy: 0.5449\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.9076 - accuracy: 0.5661\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.8166 - accuracy: 0.5865\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.7332 - accuracy: 0.6035\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.6525 - accuracy: 0.6212\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.5775 - accuracy: 0.6388\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.5038 - accuracy: 0.6541\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.4376 - accuracy: 0.6679\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.3738 - accuracy: 0.6826\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.3093 - accuracy: 0.6979\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.2416 - accuracy: 0.7150\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.1933 - accuracy: 0.7238\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.1350 - accuracy: 0.7384\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.0832 - accuracy: 0.7508\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.0375 - accuracy: 0.7585\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.9871 - accuracy: 0.7723\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.9421 - accuracy: 0.7830\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.9016 - accuracy: 0.7920\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.8579 - accuracy: 0.8026\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.8244 - accuracy: 0.8081\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.7873 - accuracy: 0.8170\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.7441 - accuracy: 0.8285\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.7143 - accuracy: 0.8351\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.6763 - accuracy: 0.8441\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.6557 - accuracy: 0.8480\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.6216 - accuracy: 0.8567\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.5897 - accuracy: 0.8657\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 0.5651 - accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "language_model('multi_rnn', 'full_seq.txt', 'glove', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 6.1233 - accuracy: 0.0399\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 89s 2ms/step - loss: 5.5315 - accuracy: 0.0682\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.0600 - accuracy: 0.1088\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 4.7151 - accuracy: 0.1413\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 89s 2ms/step - loss: 4.4169 - accuracy: 0.1715\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 89s 2ms/step - loss: 4.1252 - accuracy: 0.2054\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.8447 - accuracy: 0.2399\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 3.5719 - accuracy: 0.2773\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 3.3049 - accuracy: 0.3196\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 3.0455 - accuracy: 0.3621\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 2.8040 - accuracy: 0.4022\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.5738 - accuracy: 0.4452\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 2.3747 - accuracy: 0.4844\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 2.1752 - accuracy: 0.5259\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 2.0095 - accuracy: 0.5598\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.8420 - accuracy: 0.5944\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.6935 - accuracy: 0.6256\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.5588 - accuracy: 0.6560\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.4287 - accuracy: 0.6812\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.3177 - accuracy: 0.7056\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.2104 - accuracy: 0.7286\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.1137 - accuracy: 0.7510\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 1.0193 - accuracy: 0.7728\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.9280 - accuracy: 0.7946\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.8432 - accuracy: 0.8127\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.7763 - accuracy: 0.8274\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.7046 - accuracy: 0.8427\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.6447 - accuracy: 0.8573\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.5845 - accuracy: 0.8703\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.5292 - accuracy: 0.8838\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.4744 - accuracy: 0.8987\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.4314 - accuracy: 0.9062\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.3963 - accuracy: 0.9141\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.3585 - accuracy: 0.9231\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.3510 - accuracy: 0.9249\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.3049 - accuracy: 0.9347\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.2637 - accuracy: 0.9451\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.2348 - accuracy: 0.9513\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.2377 - accuracy: 0.9489\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.2345 - accuracy: 0.9496\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.2027 - accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1733 - accuracy: 0.9649\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1627 - accuracy: 0.9666\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1345 - accuracy: 0.9745\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1116 - accuracy: 0.9793\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1019 - accuracy: 0.9820\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1085 - accuracy: 0.9793\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1048 - accuracy: 0.9797\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1427 - accuracy: 0.9677\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.1521 - accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "language_model('bi_rnn', 'full_seq.txt', 'glove', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 48s 972us/step - loss: 6.1798 - accuracy: 0.0387\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 48s 964us/step - loss: 5.7939 - accuracy: 0.0424\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 49s 972us/step - loss: 5.4385 - accuracy: 0.0675\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 5.1141 - accuracy: 0.0937\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 47s 951us/step - loss: 4.8149 - accuracy: 0.1230\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 47s 949us/step - loss: 4.5402 - accuracy: 0.1515\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 47s 949us/step - loss: 4.2804 - accuracy: 0.1785\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 47s 949us/step - loss: 4.0442 - accuracy: 0.2037\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 47s 950us/step - loss: 3.8245 - accuracy: 0.2284\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 47s 951us/step - loss: 3.6240 - accuracy: 0.2559\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 47s 951us/step - loss: 3.4364 - accuracy: 0.2815\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 48s 952us/step - loss: 3.2638 - accuracy: 0.3094\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 48s 953us/step - loss: 3.1036 - accuracy: 0.3378\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 48s 952us/step - loss: 2.9557 - accuracy: 0.3651\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 48s 954us/step - loss: 2.8083 - accuracy: 0.3894\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 48s 959us/step - loss: 2.6708 - accuracy: 0.4161\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 48s 957us/step - loss: 2.5369 - accuracy: 0.4433\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 48s 953us/step - loss: 2.4087 - accuracy: 0.4675\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 48s 953us/step - loss: 2.2925 - accuracy: 0.4909\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 2.1785 - accuracy: 0.5142\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 48s 954us/step - loss: 2.0745 - accuracy: 0.5369\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 48s 956us/step - loss: 1.9754 - accuracy: 0.5596\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.8834 - accuracy: 0.5778\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.7994 - accuracy: 0.5951\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 48s 956us/step - loss: 1.7100 - accuracy: 0.6156\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 48s 954us/step - loss: 1.6328 - accuracy: 0.6334\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 48s 954us/step - loss: 1.5618 - accuracy: 0.6487\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.4919 - accuracy: 0.6625\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.4244 - accuracy: 0.6788\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.3573 - accuracy: 0.6958\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.2962 - accuracy: 0.7079\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 48s 954us/step - loss: 1.2449 - accuracy: 0.7204\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.1847 - accuracy: 0.7336\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.1332 - accuracy: 0.7436\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.0843 - accuracy: 0.7547\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 1.0354 - accuracy: 0.7652\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 0.9927 - accuracy: 0.7748\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 0.9484 - accuracy: 0.7862\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 48s 955us/step - loss: 0.9061 - accuracy: 0.7949\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 48s 957us/step - loss: 0.8609 - accuracy: 0.8054\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 47s 946us/step - loss: 0.8287 - accuracy: 0.8114\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 47s 947us/step - loss: 0.7882 - accuracy: 0.8221\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 47s 947us/step - loss: 0.7540 - accuracy: 0.8297\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 47s 946us/step - loss: 0.7194 - accuracy: 0.8373\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 47s 947us/step - loss: 0.6894 - accuracy: 0.8453\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 47s 946us/step - loss: 0.6615 - accuracy: 0.8507\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 47s 946us/step - loss: 0.6304 - accuracy: 0.8578\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 47s 947us/step - loss: 0.6036 - accuracy: 0.8644\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 47s 945us/step - loss: 0.5783 - accuracy: 0.8700\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 47s 947us/step - loss: 0.5502 - accuracy: 0.8765\n"
     ]
    }
   ],
   "source": [
    "language_model('rnn', 'full_seq.txt', 'glove', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model('multi_rnn', 'full_seq.txt', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 50, 50)            152200    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 50, 200)           120800    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 841,344\n",
      "Trainable params: 841,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 86s 2ms/step - loss: 6.1951 - accuracy: 0.0382\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 5.7531 - accuracy: 0.0455\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 5.4619 - accuracy: 0.0654\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 5.2581 - accuracy: 0.0812\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 5.1316 - accuracy: 0.0924\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 4.9847 - accuracy: 0.1006\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 4.8098 - accuracy: 0.1124\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 4.6627 - accuracy: 0.1251\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 4.5341 - accuracy: 0.1357\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 4.3943 - accuracy: 0.1524\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 4.2513 - accuracy: 0.1687\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 4.1069 - accuracy: 0.1878\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 3.9612 - accuracy: 0.2047\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 3.8324 - accuracy: 0.2199\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 3.6973 - accuracy: 0.2402\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 3.5615 - accuracy: 0.2552\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 3.4447 - accuracy: 0.2774\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 3.3160 - accuracy: 0.2964\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 3.1793 - accuracy: 0.3202\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 3.0688 - accuracy: 0.3397\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.9370 - accuracy: 0.3614\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.8150 - accuracy: 0.3837\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 2.7470 - accuracy: 0.3977\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 3.2144 - accuracy: 0.3039\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.9222 - accuracy: 0.3579\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.7650 - accuracy: 0.3876\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 2.6380 - accuracy: 0.4144\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.5315 - accuracy: 0.4347\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.4465 - accuracy: 0.4539\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 2.3513 - accuracy: 0.4754\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 2.2632 - accuracy: 0.4915\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.1820 - accuracy: 0.5104\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 2.1057 - accuracy: 0.5263\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 2.0344 - accuracy: 0.5418\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 1.9625 - accuracy: 0.5581\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 1.9207 - accuracy: 0.5653\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.8343 - accuracy: 0.5853\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.7669 - accuracy: 0.6012\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 1.7074 - accuracy: 0.6130\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 1.6410 - accuracy: 0.6303\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.5808 - accuracy: 0.6419\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.5264 - accuracy: 0.6554\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.4752 - accuracy: 0.6637\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.4187 - accuracy: 0.6757\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.3692 - accuracy: 0.6887\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 85s 2ms/step - loss: 1.3319 - accuracy: 0.6953\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.2755 - accuracy: 0.7094\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.2136 - accuracy: 0.7236\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.1641 - accuracy: 0.7346\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 84s 2ms/step - loss: 1.1216 - accuracy: 0.7444\n"
     ]
    }
   ],
   "source": [
    "language_model('bi_rnn', 'full_seq.txt', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 50, 50)            152200    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 610,544\n",
      "Trainable params: 610,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 45s 908us/step - loss: 6.2142 - accuracy: 0.0365\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 5.8589 - accuracy: 0.0406\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 5.6013 - accuracy: 0.0485\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 5.4184 - accuracy: 0.0604\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 5.2555 - accuracy: 0.0758\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 5.1063 - accuracy: 0.0902\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 44s 892us/step - loss: 4.9639 - accuracy: 0.1012\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 4.8173 - accuracy: 0.1133\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 4.6473 - accuracy: 0.1280\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 4.4837 - accuracy: 0.1432\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 4.3315 - accuracy: 0.1606\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 4.1902 - accuracy: 0.1777\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 4.0575 - accuracy: 0.1946\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 3.9208 - accuracy: 0.2136\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 3.7910 - accuracy: 0.2319\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 3.6667 - accuracy: 0.2481\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 3.5386 - accuracy: 0.2664\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 44s 892us/step - loss: 3.4176 - accuracy: 0.2831\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 3.3079 - accuracy: 0.3004\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 3.1919 - accuracy: 0.3199\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 3.0870 - accuracy: 0.3346\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 2.9903 - accuracy: 0.3495\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 44s 890us/step - loss: 2.8969 - accuracy: 0.3687\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 2.8031 - accuracy: 0.3858\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 2.7129 - accuracy: 0.4027\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 2.6285 - accuracy: 0.4189\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 2.5451 - accuracy: 0.4337\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 2.4705 - accuracy: 0.4500\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 2.4003 - accuracy: 0.4623\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 45s 894us/step - loss: 2.3301 - accuracy: 0.4758\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 2.2636 - accuracy: 0.4882\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 2.2002 - accuracy: 0.5049\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 2.1374 - accuracy: 0.5178\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 44s 892us/step - loss: 2.0790 - accuracy: 0.5299\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 2.0286 - accuracy: 0.5398\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 1.9739 - accuracy: 0.5514\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 1.9248 - accuracy: 0.5633\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.8737 - accuracy: 0.5732\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 45s 902us/step - loss: 1.8315 - accuracy: 0.5831\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.7865 - accuracy: 0.5924\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.7388 - accuracy: 0.6031\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.7014 - accuracy: 0.6101\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.6597 - accuracy: 0.6191\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.6191 - accuracy: 0.6275\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 44s 891us/step - loss: 1.5831 - accuracy: 0.6367\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 1.5447 - accuracy: 0.6461\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 1.5076 - accuracy: 0.6538\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 45s 893us/step - loss: 1.4758 - accuracy: 0.6611\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.4392 - accuracy: 0.6697\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 45s 892us/step - loss: 1.4024 - accuracy: 0.6772\n"
     ]
    }
   ],
   "source": [
    "language_model('rnn', 'full_seq.txt', epoc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 863,144\n",
      "Trainable params: 863,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49904/49904 [==============================] - 78s 2ms/step - loss: 6.0368 - accuracy: 0.0411\n",
      "Epoch 2/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 5.4755 - accuracy: 0.0675\n",
      "Epoch 3/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 5.0749 - accuracy: 0.1016\n",
      "Epoch 4/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 4.7336 - accuracy: 0.1377\n",
      "Epoch 5/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 4.4384 - accuracy: 0.1722\n",
      "Epoch 6/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 4.1938 - accuracy: 0.2036\n",
      "Epoch 7/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.9832 - accuracy: 0.2282\n",
      "Epoch 8/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.8236 - accuracy: 0.2478\n",
      "Epoch 9/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.6720 - accuracy: 0.2661\n",
      "Epoch 10/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.5428 - accuracy: 0.2864\n",
      "Epoch 11/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.4283 - accuracy: 0.2999\n",
      "Epoch 12/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.3086 - accuracy: 0.3187\n",
      "Epoch 13/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.2287 - accuracy: 0.3294\n",
      "Epoch 14/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.1335 - accuracy: 0.3461\n",
      "Epoch 15/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 3.0674 - accuracy: 0.3552\n",
      "Epoch 16/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.9974 - accuracy: 0.3688\n",
      "Epoch 17/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.9251 - accuracy: 0.3794\n",
      "Epoch 18/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.8833 - accuracy: 0.3864\n",
      "Epoch 19/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.8102 - accuracy: 0.3985\n",
      "Epoch 20/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.7634 - accuracy: 0.4080\n",
      "Epoch 21/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.7126 - accuracy: 0.4139\n",
      "Epoch 22/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.6996 - accuracy: 0.4186\n",
      "Epoch 23/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.6468 - accuracy: 0.4285\n",
      "Epoch 24/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.6266 - accuracy: 0.4313\n",
      "Epoch 25/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.6083 - accuracy: 0.4346\n",
      "Epoch 26/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.5742 - accuracy: 0.4391\n",
      "Epoch 27/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.5698 - accuracy: 0.4422\n",
      "Epoch 28/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.5358 - accuracy: 0.4478\n",
      "Epoch 29/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.5164 - accuracy: 0.4521\n",
      "Epoch 30/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.5045 - accuracy: 0.4492\n",
      "Epoch 31/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.4986 - accuracy: 0.4520\n",
      "Epoch 32/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.4590 - accuracy: 0.4595\n",
      "Epoch 33/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.4425 - accuracy: 0.4610\n",
      "Epoch 34/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.4179 - accuracy: 0.4672\n",
      "Epoch 35/35\n",
      "49904/49904 [==============================] - 77s 2ms/step - loss: 2.4038 - accuracy: 0.4718\n"
     ]
    }
   ],
   "source": [
    "language_model('multi_rnn', 'full_seq.txt', 'glove', bsize=128, epoc=35, lrate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model('bi_rnn', 'full_seq.txt', 'glove', bsize=128, epoc=30, lrate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 5.7458 - accuracy: 0.0600\n",
      "Epoch 2/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 4.8322 - accuracy: 0.1411\n",
      "Epoch 3/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 4.2656 - accuracy: 0.2018\n",
      "Epoch 4/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 3.8318 - accuracy: 0.2525\n",
      "Epoch 5/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 3.4922 - accuracy: 0.3002\n",
      "Epoch 6/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 3.1900 - accuracy: 0.3453\n",
      "Epoch 7/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.9309 - accuracy: 0.3850\n",
      "Epoch 8/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.7173 - accuracy: 0.4213\n",
      "Epoch 9/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.5467 - accuracy: 0.4507\n",
      "Epoch 10/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.4114 - accuracy: 0.4731\n",
      "Epoch 11/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.2830 - accuracy: 0.4951\n",
      "Epoch 12/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.1651 - accuracy: 0.5158\n",
      "Epoch 13/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 2.0659 - accuracy: 0.5346\n",
      "Epoch 14/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.9918 - accuracy: 0.5485\n",
      "Epoch 15/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.9140 - accuracy: 0.5602\n",
      "Epoch 16/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.8495 - accuracy: 0.5738\n",
      "Epoch 17/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.7839 - accuracy: 0.5862\n",
      "Epoch 18/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.7448 - accuracy: 0.5939\n",
      "Epoch 19/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.7537 - accuracy: 0.5901\n",
      "Epoch 20/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.6704 - accuracy: 0.6086\n",
      "Epoch 21/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.6264 - accuracy: 0.6171\n",
      "Epoch 22/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 1.6147 - accuracy: 0.6174\n",
      "Epoch 23/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.5735 - accuracy: 0.6255\n",
      "Epoch 24/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.5442 - accuracy: 0.6297\n",
      "Epoch 25/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 1.5126 - accuracy: 0.6354\n",
      "Epoch 26/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 1.5170 - accuracy: 0.6342\n",
      "Epoch 27/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 1.4749 - accuracy: 0.6454\n",
      "Epoch 28/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.4541 - accuracy: 0.6477\n",
      "Epoch 29/30\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 1.4555 - accuracy: 0.6460\n",
      "Epoch 30/30\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.4984 - accuracy: 0.6378\n"
     ]
    }
   ],
   "source": [
    "language_model('rnn', 'full_seq.txt', 'glove', bsize=128, epoc=30, lrate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 49s 981us/step - loss: 6.1834 - accuracy: 0.0359\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 49s 973us/step - loss: 5.8617 - accuracy: 0.0406\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 49s 987us/step - loss: 5.5702 - accuracy: 0.0552\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 49s 975us/step - loss: 5.2022 - accuracy: 0.0787\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 50s 996us/step - loss: 4.9226 - accuracy: 0.0980\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 4.6747 - accuracy: 0.1245\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 50s 994us/step - loss: 4.4470 - accuracy: 0.1497\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 48s 964us/step - loss: 4.2371 - accuracy: 0.1744\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 48s 964us/step - loss: 4.0373 - accuracy: 0.1990\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 3.8316 - accuracy: 0.2258\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 48s 964us/step - loss: 3.6415 - accuracy: 0.2533\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 48s 971us/step - loss: 3.4581 - accuracy: 0.2774\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 3.2804 - accuracy: 0.3052\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 3.1097 - accuracy: 0.3344\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.9539 - accuracy: 0.3608\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.8089 - accuracy: 0.3865\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.6741 - accuracy: 0.4141\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 2.5487 - accuracy: 0.4351\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.4234 - accuracy: 0.4622\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 2.3128 - accuracy: 0.4856\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.2134 - accuracy: 0.5054\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 2.1160 - accuracy: 0.5246\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 2.0200 - accuracy: 0.5461\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.9359 - accuracy: 0.5628\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.8532 - accuracy: 0.5834\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.7761 - accuracy: 0.5986\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.7015 - accuracy: 0.6154\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.6288 - accuracy: 0.6326\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 1.5626 - accuracy: 0.6454\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 1.5031 - accuracy: 0.6591\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.4471 - accuracy: 0.6720\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.3896 - accuracy: 0.6839\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.3354 - accuracy: 0.6962\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.2822 - accuracy: 0.7078\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.2317 - accuracy: 0.7185\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.1873 - accuracy: 0.7297\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 48s 971us/step - loss: 1.1421 - accuracy: 0.7394\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.0921 - accuracy: 0.7522\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 1.0558 - accuracy: 0.7588\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 1.0155 - accuracy: 0.7678\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.9758 - accuracy: 0.7766\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 48s 962us/step - loss: 0.9479 - accuracy: 0.7838\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 48s 961us/step - loss: 0.9064 - accuracy: 0.7946\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.8694 - accuracy: 0.8016\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.8412 - accuracy: 0.8101\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 48s 957us/step - loss: 0.8140 - accuracy: 0.8145\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.7790 - accuracy: 0.8230\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.7496 - accuracy: 0.8300\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 48s 958us/step - loss: 0.7212 - accuracy: 0.8366\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 0.6969 - accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('rnnword2vec2565010.h5', 'rnnword2vec2565010_tokenizer.pkl')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('rnn', 'full_seq.txt', embedding='word2vec', bsize=256, epoc=50, lrate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_30 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 6.1552 - accuracy: 0.0371\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.6378 - accuracy: 0.0584\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.1938 - accuracy: 0.0834\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.8706 - accuracy: 0.1124\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.5984 - accuracy: 0.1447\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.3570 - accuracy: 0.1703\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.1424 - accuracy: 0.1930\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.9308 - accuracy: 0.2167\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.7299 - accuracy: 0.2433\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.5275 - accuracy: 0.2701\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.3359 - accuracy: 0.2984\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.1542 - accuracy: 0.3281\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.9781 - accuracy: 0.3563\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.8023 - accuracy: 0.3894\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.6396 - accuracy: 0.4214\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.4956 - accuracy: 0.4503\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.3425 - accuracy: 0.4823\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.2110 - accuracy: 0.5048\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.0738 - accuracy: 0.5375\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.9544 - accuracy: 0.5621\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.8438 - accuracy: 0.5848\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.7342 - accuracy: 0.6074\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.6292 - accuracy: 0.6309\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.5309 - accuracy: 0.6533\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.4437 - accuracy: 0.6724\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.3594 - accuracy: 0.6899\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.2708 - accuracy: 0.7120\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.1964 - accuracy: 0.7285\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.1320 - accuracy: 0.7402\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.0608 - accuracy: 0.7592\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.9947 - accuracy: 0.7753\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.9326 - accuracy: 0.7885\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.8774 - accuracy: 0.8022\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.8225 - accuracy: 0.8134\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.7683 - accuracy: 0.8252\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.7234 - accuracy: 0.8366\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.6799 - accuracy: 0.8470\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.6302 - accuracy: 0.8573\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.5993 - accuracy: 0.8664\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.5578 - accuracy: 0.8769\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.5201 - accuracy: 0.8839\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.4804 - accuracy: 0.8926\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.4556 - accuracy: 0.8985\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.4384 - accuracy: 0.9022\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.3974 - accuracy: 0.9143\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.3618 - accuracy: 0.9221\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.3626 - accuracy: 0.9206\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.3417 - accuracy: 0.9234\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.3076 - accuracy: 0.9335\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.2784 - accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bi_rnnword2vec2565010.h5', 'bi_rnnword2vec2565010_tokenizer.pkl')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('bi_rnn', 'full_seq.txt', embedding='word2vec', bsize=256, epoc=50, lrate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 863,144\n",
      "Trainable params: 863,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49904/49904 [==============================] - 71s 1ms/step - loss: 6.2013 - accuracy: 0.0377\n",
      "Epoch 2/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 5.9708 - accuracy: 0.0396\n",
      "Epoch 3/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 5.9636 - accuracy: 0.0397\n",
      "Epoch 4/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 5.7553 - accuracy: 0.0421\n",
      "Epoch 5/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 5.3716 - accuracy: 0.0620\n",
      "Epoch 6/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 5.0958 - accuracy: 0.0788\n",
      "Epoch 7/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.8758 - accuracy: 0.0974\n",
      "Epoch 8/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.6699 - accuracy: 0.1150\n",
      "Epoch 9/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.4774 - accuracy: 0.1362\n",
      "Epoch 10/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.2751 - accuracy: 0.1616\n",
      "Epoch 11/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 4.0917 - accuracy: 0.1849\n",
      "Epoch 12/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.9101 - accuracy: 0.2087\n",
      "Epoch 13/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.7527 - accuracy: 0.2287\n",
      "Epoch 14/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.5959 - accuracy: 0.2506\n",
      "Epoch 15/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.4621 - accuracy: 0.2734\n",
      "Epoch 16/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.3357 - accuracy: 0.2902\n",
      "Epoch 17/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.2148 - accuracy: 0.3105\n",
      "Epoch 18/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 3.1030 - accuracy: 0.3293\n",
      "Epoch 19/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.9952 - accuracy: 0.3475\n",
      "Epoch 20/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.8912 - accuracy: 0.3693\n",
      "Epoch 21/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.7989 - accuracy: 0.3837\n",
      "Epoch 22/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.7078 - accuracy: 0.4021\n",
      "Epoch 23/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.6117 - accuracy: 0.4207\n",
      "Epoch 24/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.5355 - accuracy: 0.4354\n",
      "Epoch 25/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.4460 - accuracy: 0.4541\n",
      "Epoch 26/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.3751 - accuracy: 0.4695\n",
      "Epoch 27/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.3003 - accuracy: 0.4831\n",
      "Epoch 28/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.2272 - accuracy: 0.4987\n",
      "Epoch 29/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.1630 - accuracy: 0.5100\n",
      "Epoch 30/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.0957 - accuracy: 0.5241\n",
      "Epoch 31/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 2.0340 - accuracy: 0.5384\n",
      "Epoch 32/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.9648 - accuracy: 0.5527\n",
      "Epoch 33/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.9128 - accuracy: 0.5650\n",
      "Epoch 34/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.8571 - accuracy: 0.5736\n",
      "Epoch 35/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.8038 - accuracy: 0.5875\n",
      "Epoch 36/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.7465 - accuracy: 0.6000\n",
      "Epoch 37/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.7019 - accuracy: 0.6083\n",
      "Epoch 38/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.6527 - accuracy: 0.6196\n",
      "Epoch 39/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.6063 - accuracy: 0.6285\n",
      "Epoch 40/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.5674 - accuracy: 0.6375\n",
      "Epoch 41/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.5229 - accuracy: 0.6468\n",
      "Epoch 42/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.4709 - accuracy: 0.6608\n",
      "Epoch 43/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.4334 - accuracy: 0.6676\n",
      "Epoch 44/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.3941 - accuracy: 0.6759\n",
      "Epoch 45/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.3526 - accuracy: 0.6854\n",
      "Epoch 46/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.3239 - accuracy: 0.6894\n",
      "Epoch 47/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.2871 - accuracy: 0.6989\n",
      "Epoch 48/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.2507 - accuracy: 0.7057\n",
      "Epoch 49/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.2133 - accuracy: 0.7164\n",
      "Epoch 50/50\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.1836 - accuracy: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('multi_rnnword2vec2565010.h5', 'multi_rnnword2vec2565010_tokenizer.pkl')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('multi_rnn', 'full_seq.txt', embedding='word2vec', bsize=256, epoc=50, lrate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49904/49904 [==============================] - 108s 2ms/step - loss: 6.1241 - accuracy: 0.0383\n",
      "Epoch 2/5\n",
      "49904/49904 [==============================] - 104s 2ms/step - loss: 5.6058 - accuracy: 0.0632\n",
      "Epoch 3/5\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 5.1325 - accuracy: 0.1020\n",
      "Epoch 4/5\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.7427 - accuracy: 0.1366\n",
      "Epoch 5/5\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.4016 - accuracy: 0.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "tonight and i see you were the hill of the mountain of the woman's side and i see you were the hill of the mountain of the woman's side and i see you were the mountain of the woman's tonight and i see you were the hill of the woman's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_21 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "49904/49904 [==============================] - 94s 2ms/step - loss: 6.1178 - accuracy: 0.0388\n",
      "Epoch 2/15\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 5.5378 - accuracy: 0.0705\n",
      "Epoch 3/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.0478 - accuracy: 0.1114\n",
      "Epoch 4/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.6466 - accuracy: 0.1482\n",
      "Epoch 5/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.3185 - accuracy: 0.1838\n",
      "Epoch 6/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.0379 - accuracy: 0.2141\n",
      "Epoch 7/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.7735 - accuracy: 0.2484\n",
      "Epoch 8/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.5166 - accuracy: 0.2871\n",
      "Epoch 9/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.2665 - accuracy: 0.3241\n",
      "Epoch 10/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.0209 - accuracy: 0.3665\n",
      "Epoch 11/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.7849 - accuracy: 0.4089\n",
      "Epoch 12/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.5635 - accuracy: 0.4510\n",
      "Epoch 13/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.3550 - accuracy: 0.4908\n",
      "Epoch 14/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.1657 - accuracy: 0.5284\n",
      "Epoch 15/15\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.9876 - accuracy: 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of the age of water i only show the phone but i've got to the age of the age of the age of the riches stuck in the second girl and a boy that lives they got a keep in the resurrection's tee and i know that we've been\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 6.1005 - accuracy: 0.0400\n",
      "Epoch 2/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.5316 - accuracy: 0.0755\n",
      "Epoch 3/25\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 5.0346 - accuracy: 0.1135\n",
      "Epoch 4/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.6544 - accuracy: 0.1490\n",
      "Epoch 5/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.3073 - accuracy: 0.1860\n",
      "Epoch 6/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 4.0243 - accuracy: 0.2172\n",
      "Epoch 7/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.7269 - accuracy: 0.2556\n",
      "Epoch 8/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.4475 - accuracy: 0.2969\n",
      "Epoch 9/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 3.1701 - accuracy: 0.3424\n",
      "Epoch 10/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.9137 - accuracy: 0.3879\n",
      "Epoch 11/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.6632 - accuracy: 0.4341\n",
      "Epoch 12/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.4319 - accuracy: 0.4769\n",
      "Epoch 13/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.2233 - accuracy: 0.5198\n",
      "Epoch 14/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 2.0279 - accuracy: 0.5575\n",
      "Epoch 15/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.8471 - accuracy: 0.5940\n",
      "Epoch 16/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.6792 - accuracy: 0.6309\n",
      "Epoch 17/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.5318 - accuracy: 0.6617\n",
      "Epoch 18/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.4076 - accuracy: 0.6863\n",
      "Epoch 19/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.3334 - accuracy: 0.7008\n",
      "Epoch 20/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.1627 - accuracy: 0.7406\n",
      "Epoch 21/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 1.0591 - accuracy: 0.7619\n",
      "Epoch 22/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.9742 - accuracy: 0.7822\n",
      "Epoch 23/25\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 0.8744 - accuracy: 0.8031\n",
      "Epoch 24/25\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.7855 - accuracy: 0.8243\n",
      "Epoch 25/25\n",
      "49904/49904 [==============================] - 90s 2ms/step - loss: 0.7097 - accuracy: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of stone and your brother whispering now for the no to make the bank and everyday that someone's got to pay me i gave you my genre i'm still getting for phrases this been for the time that every day in the time that can be asking me i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 6.0974 - accuracy: 0.0376\n",
      "Epoch 2/35\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.5356 - accuracy: 0.0690\n",
      "Epoch 3/35\n",
      "49904/49904 [==============================] - 91s 2ms/step - loss: 5.0858 - accuracy: 0.1095\n",
      "Epoch 4/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.7139 - accuracy: 0.1392\n",
      "Epoch 5/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.3893 - accuracy: 0.1769\n",
      "Epoch 6/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.0880 - accuracy: 0.2117\n",
      "Epoch 7/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.8024 - accuracy: 0.2485\n",
      "Epoch 8/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.5257 - accuracy: 0.2880\n",
      "Epoch 9/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.2479 - accuracy: 0.3291\n",
      "Epoch 10/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.9699 - accuracy: 0.3773\n",
      "Epoch 11/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.6957 - accuracy: 0.4253\n",
      "Epoch 12/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.4466 - accuracy: 0.4737\n",
      "Epoch 13/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.2269 - accuracy: 0.5193\n",
      "Epoch 14/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.0180 - accuracy: 0.5595\n",
      "Epoch 15/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.8370 - accuracy: 0.5958\n",
      "Epoch 16/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.6670 - accuracy: 0.6333\n",
      "Epoch 17/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.5102 - accuracy: 0.6665\n",
      "Epoch 18/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.3755 - accuracy: 0.6949\n",
      "Epoch 19/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.2500 - accuracy: 0.7215\n",
      "Epoch 20/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.1377 - accuracy: 0.7466\n",
      "Epoch 21/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.0279 - accuracy: 0.7723\n",
      "Epoch 22/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.9314 - accuracy: 0.7929\n",
      "Epoch 23/35\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 0.8451 - accuracy: 0.8129\n",
      "Epoch 24/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.7636 - accuracy: 0.8309\n",
      "Epoch 25/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.6946 - accuracy: 0.8462\n",
      "Epoch 26/35\n",
      "49904/49904 [==============================] - 95s 2ms/step - loss: 0.6272 - accuracy: 0.8615\n",
      "Epoch 27/35\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 0.5654 - accuracy: 0.8752\n",
      "Epoch 28/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.5081 - accuracy: 0.8870\n",
      "Epoch 29/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.4522 - accuracy: 0.9003\n",
      "Epoch 30/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3993 - accuracy: 0.9131\n",
      "Epoch 31/35\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 0.4193 - accuracy: 0.9046\n",
      "Epoch 32/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3552 - accuracy: 0.9214\n",
      "Epoch 33/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3177 - accuracy: 0.9307\n",
      "Epoch 34/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.2962 - accuracy: 0.9352\n",
      "Epoch 35/35\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.2442 - accuracy: 0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of less cash and i know this to be but tragically our love just fun i was to give you wide tell you that it take it back can change your eyes until my soul is my head at your head are a year i'm living and may i\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "bidirectional_27 (Bidirectio (None, 50, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 1,033,544\n",
      "Trainable params: 1,033,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 6.1011 - accuracy: 0.0390\n",
      "Epoch 2/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 5.5148 - accuracy: 0.0759\n",
      "Epoch 3/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 5.0495 - accuracy: 0.1155\n",
      "Epoch 4/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.6475 - accuracy: 0.1512\n",
      "Epoch 5/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.3181 - accuracy: 0.1859\n",
      "Epoch 6/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 4.0203 - accuracy: 0.2205\n",
      "Epoch 7/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.7461 - accuracy: 0.2567\n",
      "Epoch 8/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.4845 - accuracy: 0.2919\n",
      "Epoch 9/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 3.2228 - accuracy: 0.3327\n",
      "Epoch 10/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.9864 - accuracy: 0.3724\n",
      "Epoch 11/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.7371 - accuracy: 0.4143\n",
      "Epoch 12/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.5072 - accuracy: 0.4580\n",
      "Epoch 13/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.3056 - accuracy: 0.4995\n",
      "Epoch 14/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 2.1086 - accuracy: 0.5393\n",
      "Epoch 15/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.9229 - accuracy: 0.5771\n",
      "Epoch 16/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.7579 - accuracy: 0.6147\n",
      "Epoch 17/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.6056 - accuracy: 0.6479\n",
      "Epoch 18/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.4704 - accuracy: 0.6769\n",
      "Epoch 19/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.3360 - accuracy: 0.7055\n",
      "Epoch 20/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.2282 - accuracy: 0.7299\n",
      "Epoch 21/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.1291 - accuracy: 0.7500\n",
      "Epoch 22/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 1.0210 - accuracy: 0.7732\n",
      "Epoch 23/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.9157 - accuracy: 0.7987\n",
      "Epoch 24/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.8354 - accuracy: 0.8149\n",
      "Epoch 25/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.7583 - accuracy: 0.8325\n",
      "Epoch 26/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.6894 - accuracy: 0.8468\n",
      "Epoch 27/45\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 0.6339 - accuracy: 0.8587\n",
      "Epoch 28/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.5679 - accuracy: 0.8747\n",
      "Epoch 29/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.5130 - accuracy: 0.8880\n",
      "Epoch 30/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.4579 - accuracy: 0.9000\n",
      "Epoch 31/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.4143 - accuracy: 0.9091\n",
      "Epoch 32/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3758 - accuracy: 0.9185\n",
      "Epoch 33/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3393 - accuracy: 0.9277\n",
      "Epoch 34/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.3049 - accuracy: 0.9348\n",
      "Epoch 35/45\n",
      "49904/49904 [==============================] - 93s 2ms/step - loss: 0.2927 - accuracy: 0.9369\n",
      "Epoch 36/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.2574 - accuracy: 0.9448\n",
      "Epoch 37/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.2166 - accuracy: 0.9555\n",
      "Epoch 38/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1814 - accuracy: 0.9656\n",
      "Epoch 39/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1690 - accuracy: 0.9675\n",
      "Epoch 40/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1459 - accuracy: 0.9730\n",
      "Epoch 41/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1346 - accuracy: 0.9748\n",
      "Epoch 42/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1251 - accuracy: 0.9763\n",
      "Epoch 43/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1662 - accuracy: 0.9635\n",
      "Epoch 44/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1994 - accuracy: 0.9524\n",
      "Epoch 45/45\n",
      "49904/49904 [==============================] - 92s 2ms/step - loss: 0.1590 - accuracy: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of less cash and i guess that i've got too much because the memories of me i can i thought i'd never dies but i say it i would be get all that's all my phone and i need to get all or start it in now things keep\n"
     ]
    }
   ],
   "source": [
    "bleu_df = pd.DataFrame(columns=['epochs', '1_gram', '2_gram', '3_gram', '4_gram'])\n",
    "for i in [5, 15, 25, 35, 45]:\n",
    "    mname, tokens = language_model('bi_rnn', 'full_seq.txt', 'glove', epoc=i)\n",
    "    g_1, g_2, g_3, g_4 = generate_song('test_seq.txt', mname, tokens)\n",
    "    df = pd.DataFrame([[i, g_1, g_2, g_3, g_4]], columns=['epochs', '1_gram', '2_gram', '3_gram', '4_gram'])\n",
    "    bleu_df = bleu_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(bleu_df['epochs'], bleu_df['2_gram'], label='Training accuracy')\n",
    "plt.title('BLEU Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BLEU Score')\n",
    "# plt.xticks(range(5, len(list(bleu_df['epochs'])) + 10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>1_gram</th>\n",
       "      <th>2_gram</th>\n",
       "      <th>3_gram</th>\n",
       "      <th>4_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.215644</td>\n",
       "      <td>0.065679</td>\n",
       "      <td>9.799083e-94</td>\n",
       "      <td>3.784800e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.215644</td>\n",
       "      <td>0.113760</td>\n",
       "      <td>1.362454e-93</td>\n",
       "      <td>4.981077e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.254852</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>1.030269e-93</td>\n",
       "      <td>3.946214e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0.372475</td>\n",
       "      <td>0.228379</td>\n",
       "      <td>1.940731e-01</td>\n",
       "      <td>1.277750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0.392079</td>\n",
       "      <td>0.234312</td>\n",
       "      <td>2.225747e-01</td>\n",
       "      <td>1.627422e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epochs    1_gram    2_gram        3_gram         4_gram\n",
       "0      5  0.215644  0.065679  9.799083e-94  3.784800e-155\n",
       "1     15  0.215644  0.113760  1.362454e-93  4.981077e-155\n",
       "2     25  0.254852  0.071401  1.030269e-93  3.946214e-155\n",
       "3     35  0.372475  0.228379  1.940731e-01   1.277750e-01\n",
       "4     45  0.392079  0.234312  2.225747e-01   1.627422e-01"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49904/49904 [==============================] - 50s 998us/step - loss: 6.1861 - accuracy: 0.0355\n",
      "Epoch 2/5\n",
      "49904/49904 [==============================] - 50s 997us/step - loss: 5.7365 - accuracy: 0.0463\n",
      "Epoch 3/5\n",
      "49904/49904 [==============================] - 51s 1ms/step - loss: 5.3741 - accuracy: 0.0747\n",
      "Epoch 4/5\n",
      "49904/49904 [==============================] - 50s 997us/step - loss: 5.0631 - accuracy: 0.0983\n",
      "Epoch 5/5\n",
      "49904/49904 [==============================] - 49s 980us/step - loss: 4.7782 - accuracy: 0.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "one and i see the la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "49904/49904 [==============================] - 51s 1ms/step - loss: 6.1659 - accuracy: 0.0399\n",
      "Epoch 2/15\n",
      "49904/49904 [==============================] - 49s 974us/step - loss: 5.7554 - accuracy: 0.0459\n",
      "Epoch 3/15\n",
      "49904/49904 [==============================] - 49s 977us/step - loss: 5.3984 - accuracy: 0.0729\n",
      "Epoch 4/15\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 5.0709 - accuracy: 0.0990\n",
      "Epoch 5/15\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 4.7798 - accuracy: 0.1259\n",
      "Epoch 6/15\n",
      "49904/49904 [==============================] - 49s 986us/step - loss: 4.4984 - accuracy: 0.1564\n",
      "Epoch 7/15\n",
      "49904/49904 [==============================] - 49s 986us/step - loss: 4.2509 - accuracy: 0.1817\n",
      "Epoch 8/15\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 4.0226 - accuracy: 0.2060\n",
      "Epoch 9/15\n",
      "49904/49904 [==============================] - 48s 970us/step - loss: 3.8178 - accuracy: 0.2304\n",
      "Epoch 10/15\n",
      "49904/49904 [==============================] - 48s 960us/step - loss: 3.6213 - accuracy: 0.2561\n",
      "Epoch 11/15\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 3.4338 - accuracy: 0.2836\n",
      "Epoch 12/15\n",
      "49904/49904 [==============================] - 48s 972us/step - loss: 3.2626 - accuracy: 0.3124\n",
      "Epoch 13/15\n",
      "49904/49904 [==============================] - 49s 984us/step - loss: 3.0895 - accuracy: 0.3437\n",
      "Epoch 14/15\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 2.9354 - accuracy: 0.3698\n",
      "Epoch 15/15\n",
      "49904/49904 [==============================] - 48s 970us/step - loss: 2.7845 - accuracy: 0.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "air of the setting song i know isn't on the sweet is me to be my people stop my friends and tasted the sweet perfume of the mountain side desolation comes upon the hill over the castle on the hill over the castle on the hill over the castle on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49904/49904 [==============================] - 49s 990us/step - loss: 6.1757 - accuracy: 0.0370\n",
      "Epoch 2/25\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 5.7630 - accuracy: 0.0446\n",
      "Epoch 3/25\n",
      "49904/49904 [==============================] - 50s 997us/step - loss: 5.3719 - accuracy: 0.0792\n",
      "Epoch 4/25\n",
      "49904/49904 [==============================] - 48s 969us/step - loss: 5.0073 - accuracy: 0.1097\n",
      "Epoch 5/25\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 4.6871 - accuracy: 0.1422\n",
      "Epoch 6/25\n",
      "49904/49904 [==============================] - 48s 963us/step - loss: 4.3978 - accuracy: 0.1714\n",
      "Epoch 7/25\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 4.1340 - accuracy: 0.2016\n",
      "Epoch 8/25\n",
      "49904/49904 [==============================] - 49s 972us/step - loss: 3.8873 - accuracy: 0.2279\n",
      "Epoch 9/25\n",
      "49904/49904 [==============================] - 48s 962us/step - loss: 3.6550 - accuracy: 0.2585\n",
      "Epoch 10/25\n",
      "49904/49904 [==============================] - 50s 999us/step - loss: 3.4479 - accuracy: 0.2873\n",
      "Epoch 11/25\n",
      "49904/49904 [==============================] - 57s 1ms/step - loss: 3.2448 - accuracy: 0.3202\n",
      "Epoch 12/25\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 3.0561 - accuracy: 0.3513\n",
      "Epoch 13/25\n",
      "49904/49904 [==============================] - 49s 978us/step - loss: 2.8768 - accuracy: 0.3827\n",
      "Epoch 14/25\n",
      "49904/49904 [==============================] - 48s 963us/step - loss: 2.7161 - accuracy: 0.4116\n",
      "Epoch 15/25\n",
      "49904/49904 [==============================] - 49s 974us/step - loss: 2.5580 - accuracy: 0.4445\n",
      "Epoch 16/25\n",
      "49904/49904 [==============================] - 48s 969us/step - loss: 2.4091 - accuracy: 0.4726\n",
      "Epoch 17/25\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 2.2746 - accuracy: 0.4987\n",
      "Epoch 18/25\n",
      "49904/49904 [==============================] - 49s 980us/step - loss: 2.1405 - accuracy: 0.5261\n",
      "Epoch 19/25\n",
      "49904/49904 [==============================] - 49s 978us/step - loss: 2.0248 - accuracy: 0.5505\n",
      "Epoch 20/25\n",
      "49904/49904 [==============================] - 51s 1ms/step - loss: 1.9117 - accuracy: 0.5730\n",
      "Epoch 21/25\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.8018 - accuracy: 0.5980\n",
      "Epoch 22/25\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.7040 - accuracy: 0.6205\n",
      "Epoch 23/25\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 1.6128 - accuracy: 0.6372\n",
      "Epoch 24/25\n",
      "49904/49904 [==============================] - 49s 978us/step - loss: 1.5214 - accuracy: 0.6572\n",
      "Epoch 25/25\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 1.4375 - accuracy: 0.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of water the sun comes up playing fast and i know me and i do to see you can fade apart i'm gonna do i know that i wanna know about talking for the right to raise of the right to catch you back and i don't wanna know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "49904/49904 [==============================] - 50s 995us/step - loss: 6.1703 - accuracy: 0.0375\n",
      "Epoch 2/35\n",
      "49904/49904 [==============================] - 49s 972us/step - loss: 5.7728 - accuracy: 0.0432\n",
      "Epoch 3/35\n",
      "49904/49904 [==============================] - 48s 967us/step - loss: 5.4445 - accuracy: 0.0704\n",
      "Epoch 4/35\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 5.1013 - accuracy: 0.1001\n",
      "Epoch 5/35\n",
      "49904/49904 [==============================] - 49s 974us/step - loss: 4.8015 - accuracy: 0.1258\n",
      "Epoch 6/35\n",
      "49904/49904 [==============================] - 48s 971us/step - loss: 4.5350 - accuracy: 0.1517\n",
      "Epoch 7/35\n",
      "49904/49904 [==============================] - 49s 979us/step - loss: 4.3003 - accuracy: 0.1772\n",
      "Epoch 8/35\n",
      "49904/49904 [==============================] - 49s 972us/step - loss: 4.0832 - accuracy: 0.2030\n",
      "Epoch 9/35\n",
      "49904/49904 [==============================] - 48s 971us/step - loss: 3.8775 - accuracy: 0.2298\n",
      "Epoch 10/35\n",
      "49904/49904 [==============================] - 48s 969us/step - loss: 3.6671 - accuracy: 0.2543\n",
      "Epoch 11/35\n",
      "49904/49904 [==============================] - 48s 969us/step - loss: 3.4637 - accuracy: 0.2820\n",
      "Epoch 12/35\n",
      "49904/49904 [==============================] - 48s 962us/step - loss: 3.2738 - accuracy: 0.3113\n",
      "Epoch 13/35\n",
      "49904/49904 [==============================] - 49s 976us/step - loss: 3.0924 - accuracy: 0.3416\n",
      "Epoch 14/35\n",
      "49904/49904 [==============================] - 49s 983us/step - loss: 2.9224 - accuracy: 0.3722\n",
      "Epoch 15/35\n",
      "49904/49904 [==============================] - 49s 983us/step - loss: 2.7604 - accuracy: 0.4019\n",
      "Epoch 16/35\n",
      "49904/49904 [==============================] - 49s 974us/step - loss: 2.6078 - accuracy: 0.4293\n",
      "Epoch 17/35\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 2.4696 - accuracy: 0.4558\n",
      "Epoch 18/35\n",
      "49904/49904 [==============================] - 49s 976us/step - loss: 2.3328 - accuracy: 0.4840\n",
      "Epoch 19/35\n",
      "49904/49904 [==============================] - 49s 972us/step - loss: 2.2093 - accuracy: 0.5091\n",
      "Epoch 20/35\n",
      "49904/49904 [==============================] - 49s 985us/step - loss: 2.0856 - accuracy: 0.5362\n",
      "Epoch 21/35\n",
      "49904/49904 [==============================] - 49s 975us/step - loss: 1.9823 - accuracy: 0.5575\n",
      "Epoch 22/35\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 1.8813 - accuracy: 0.5792\n",
      "Epoch 23/35\n",
      "49904/49904 [==============================] - 50s 994us/step - loss: 1.7796 - accuracy: 0.6027\n",
      "Epoch 24/35\n",
      "49904/49904 [==============================] - 50s 995us/step - loss: 1.6899 - accuracy: 0.6214\n",
      "Epoch 25/35\n",
      "49904/49904 [==============================] - 48s 971us/step - loss: 1.6023 - accuracy: 0.6419\n",
      "Epoch 26/35\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 1.5229 - accuracy: 0.6588\n",
      "Epoch 27/35\n",
      "49904/49904 [==============================] - 48s 969us/step - loss: 1.4476 - accuracy: 0.6765\n",
      "Epoch 28/35\n",
      "49904/49904 [==============================] - 49s 978us/step - loss: 1.3758 - accuracy: 0.6923\n",
      "Epoch 29/35\n",
      "49904/49904 [==============================] - 48s 965us/step - loss: 1.3059 - accuracy: 0.7065\n",
      "Epoch 30/35\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 1.2489 - accuracy: 0.7188\n",
      "Epoch 31/35\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 1.1870 - accuracy: 0.7335\n",
      "Epoch 32/35\n",
      "49904/49904 [==============================] - 49s 973us/step - loss: 1.1298 - accuracy: 0.7448\n",
      "Epoch 33/35\n",
      "49904/49904 [==============================] - 49s 983us/step - loss: 1.0713 - accuracy: 0.7602\n",
      "Epoch 34/35\n",
      "49904/49904 [==============================] - 49s 982us/step - loss: 1.0221 - accuracy: 0.7688\n",
      "Epoch 35/35\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 0.9696 - accuracy: 0.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of times it's all passes by jeans c'mon and tequila i hope that things is me but when i'm not through minimum things you know much to make it inside this whole town's never have my feet for a plate we talk for hours oh she knows me like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/affine/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 50, 100)           304400    \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 3044)              307444    \n",
      "=================================================================\n",
      "Total params: 782,744\n",
      "Trainable params: 782,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 6.1847 - accuracy: 0.0394\n",
      "Epoch 2/45\n",
      "49904/49904 [==============================] - 49s 985us/step - loss: 5.7039 - accuracy: 0.0487\n",
      "Epoch 3/45\n",
      "49904/49904 [==============================] - 49s 983us/step - loss: 5.3058 - accuracy: 0.0790\n",
      "Epoch 4/45\n",
      "49904/49904 [==============================] - 49s 983us/step - loss: 5.0053 - accuracy: 0.1044\n",
      "Epoch 5/45\n",
      "49904/49904 [==============================] - 49s 976us/step - loss: 4.6934 - accuracy: 0.1346\n",
      "Epoch 6/45\n",
      "49904/49904 [==============================] - 49s 973us/step - loss: 4.4027 - accuracy: 0.1605\n",
      "Epoch 7/45\n",
      "49904/49904 [==============================] - 48s 968us/step - loss: 4.1393 - accuracy: 0.1933\n",
      "Epoch 8/45\n",
      "49904/49904 [==============================] - 48s 966us/step - loss: 3.8987 - accuracy: 0.2230\n",
      "Epoch 9/45\n",
      "49904/49904 [==============================] - 49s 973us/step - loss: 3.6864 - accuracy: 0.2477\n",
      "Epoch 10/45\n",
      "49904/49904 [==============================] - 49s 991us/step - loss: 3.4776 - accuracy: 0.2779\n",
      "Epoch 11/45\n",
      "49904/49904 [==============================] - 50s 995us/step - loss: 3.2769 - accuracy: 0.3091\n",
      "Epoch 12/45\n",
      "49904/49904 [==============================] - 51s 1ms/step - loss: 3.0864 - accuracy: 0.3390\n",
      "Epoch 13/45\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 2.9064 - accuracy: 0.3724\n",
      "Epoch 14/45\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 2.7457 - accuracy: 0.4022\n",
      "Epoch 15/45\n",
      "49904/49904 [==============================] - 55s 1ms/step - loss: 2.5928 - accuracy: 0.4324\n",
      "Epoch 16/45\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 2.4510 - accuracy: 0.4614\n",
      "Epoch 17/45\n",
      "49904/49904 [==============================] - 49s 980us/step - loss: 2.3217 - accuracy: 0.4871\n",
      "Epoch 18/45\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 2.1987 - accuracy: 0.5108\n",
      "Epoch 19/45\n",
      "49904/49904 [==============================] - 56s 1ms/step - loss: 2.0806 - accuracy: 0.5376\n",
      "Epoch 20/45\n",
      "49904/49904 [==============================] - 50s 994us/step - loss: 1.9744 - accuracy: 0.5603\n",
      "Epoch 21/45\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 1.8720 - accuracy: 0.5833\n",
      "Epoch 22/45\n",
      "49904/49904 [==============================] - 50s 1ms/step - loss: 1.7778 - accuracy: 0.6015\n",
      "Epoch 23/45\n",
      "49904/49904 [==============================] - 67s 1ms/step - loss: 1.6857 - accuracy: 0.6217\n",
      "Epoch 24/45\n",
      "49904/49904 [==============================] - 69s 1ms/step - loss: 1.6045 - accuracy: 0.6393\n",
      "Epoch 25/45\n",
      "49904/49904 [==============================] - 78s 2ms/step - loss: 1.5234 - accuracy: 0.6582\n",
      "Epoch 26/45\n",
      "49904/49904 [==============================] - 70s 1ms/step - loss: 1.4487 - accuracy: 0.6722\n",
      "Epoch 27/45\n",
      "49904/49904 [==============================] - 67s 1ms/step - loss: 1.3763 - accuracy: 0.6889\n",
      "Epoch 28/45\n",
      "49904/49904 [==============================] - 66s 1ms/step - loss: 1.3052 - accuracy: 0.7046\n",
      "Epoch 29/45\n",
      "49904/49904 [==============================] - 61s 1ms/step - loss: 1.2456 - accuracy: 0.7179\n",
      "Epoch 30/45\n",
      "49904/49904 [==============================] - 68s 1ms/step - loss: 1.1816 - accuracy: 0.7325\n",
      "Epoch 31/45\n",
      "49904/49904 [==============================] - 74s 1ms/step - loss: 1.1206 - accuracy: 0.7472\n",
      "Epoch 32/45\n",
      "49904/49904 [==============================] - 64s 1ms/step - loss: 1.0688 - accuracy: 0.7594\n",
      "Epoch 33/45\n",
      "49904/49904 [==============================] - 58s 1ms/step - loss: 1.0143 - accuracy: 0.7715\n",
      "Epoch 34/45\n",
      "49904/49904 [==============================] - 64s 1ms/step - loss: 0.9667 - accuracy: 0.7811\n",
      "Epoch 35/45\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 0.9186 - accuracy: 0.7935\n",
      "Epoch 36/45\n",
      "49904/49904 [==============================] - 49s 991us/step - loss: 0.8747 - accuracy: 0.8021\n",
      "Epoch 37/45\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 0.8320 - accuracy: 0.8126\n",
      "Epoch 38/45\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 0.7943 - accuracy: 0.8189\n",
      "Epoch 39/45\n",
      "49904/49904 [==============================] - 51s 1ms/step - loss: 0.7464 - accuracy: 0.8308\n",
      "Epoch 40/45\n",
      "49904/49904 [==============================] - 54s 1ms/step - loss: 0.7130 - accuracy: 0.8393\n",
      "Epoch 41/45\n",
      "49904/49904 [==============================] - 53s 1ms/step - loss: 0.6770 - accuracy: 0.8466\n",
      "Epoch 42/45\n",
      "49904/49904 [==============================] - 52s 1ms/step - loss: 0.6451 - accuracy: 0.8538\n",
      "Epoch 43/45\n",
      "49904/49904 [==============================] - 60s 1ms/step - loss: 0.6086 - accuracy: 0.8620\n",
      "Epoch 44/45\n",
      "49904/49904 [==============================] - 72s 1ms/step - loss: 0.5852 - accuracy: 0.8674\n",
      "Epoch 45/45\n",
      "49904/49904 [==============================] - 68s 1ms/step - loss: 0.5519 - accuracy: 0.8753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "monastery i'm not cut out for life on the road cause i didn't know i'd miss you this much and at the time we'd just go so sue me i guess i'm not the man that you need ever since you went to uni i've been sofa surfing with a rucksack\n",
      "\n",
      "Actual text -----\n",
      "full of less cash and i guess that could get bad but when i broke the industry that's when i broke your heart i was supposed to chart and celebrate but good things are over fast i know it's hard to deal with and see this i tend to turn you\n",
      "\n",
      "Predicted text -----\n",
      "full of less cash and i guess that don't wish it i need to get on the pain that blessed me with the days off their old old notes and jet lagged never never had the lyrics plus prove you does the dj slept in the sink dad always told\n"
     ]
    }
   ],
   "source": [
    "bleu_df_2 = pd.DataFrame(columns=['epochs', '1_gram', '2_gram', '3_gram', '4_gram'])\n",
    "for i in [5, 15, 25, 35, 45]:\n",
    "    mname, tokens = language_model('rnn', 'full_seq.txt', 'glove', epoc=i)\n",
    "    g_1, g_2, g_3, g_4 = generate_song('test_seq.txt', mname, tokens)\n",
    "    df = pd.DataFrame([[i, g_1, g_2, g_3, g_4]], columns=['epochs', '1_gram', '2_gram', '3_gram', '4_gram'])\n",
    "    bleu_df_2 = bleu_df_2.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(bleu_df_2['epochs'], bleu_df_2['2_gram'], label='Training accuracy')\n",
    "plt.title('BLEU Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('BLEU Score')\n",
    "# plt.xticks(range(5, len(list(bleu_df['epochs'])) + 10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>1_gram</th>\n",
       "      <th>2_gram</th>\n",
       "      <th>3_gram</th>\n",
       "      <th>4_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>0.039606</td>\n",
       "      <td>7.234118e-94</td>\n",
       "      <td>2.939069e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.137228</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>8.556517e-94</td>\n",
       "      <td>3.380410e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.372475</td>\n",
       "      <td>0.149509</td>\n",
       "      <td>1.605203e-93</td>\n",
       "      <td>5.710360e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0.254852</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>1.268410e-93</td>\n",
       "      <td>4.692866e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0.294060</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>2.041710e-01</td>\n",
       "      <td>1.514487e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epochs    1_gram    2_gram        3_gram         4_gram\n",
       "0      5  0.078416  0.039606  7.234118e-94  2.939069e-155\n",
       "1     15  0.137228  0.052394  8.556517e-94  3.380410e-155\n",
       "2     25  0.372475  0.149509  1.605203e-93  5.710360e-155\n",
       "3     35  0.254852  0.100976  1.268410e-93  4.692866e-155\n",
       "4     45  0.294060  0.202920  2.041710e-01   1.514487e-01"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(input_lyrics, model_file, tokenizer_pickle_file, seq_length=50):\n",
    "    \"\"\"\n",
    "    Function to generate a new lyrics\n",
    "    \n",
    "    # Arguments\n",
    "        input_lyrics: Input lyrics of size 50 words used to predict the next 50 words\n",
    "        model_file: Path of trained model to be used for prediction\n",
    "        tokenizer_pickle_file: Path of tokenizer pickle file to be used\n",
    "        \n",
    "    # Returns\n",
    "        Prints the input sequence, sequence to be followed & predicted sequence and\n",
    "        returns Bleu scores considering 1, 2, 3, 4 - grams\n",
    "    \"\"\"\n",
    "\n",
    "    # generate a sequence from a language model\n",
    "    def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "        result = list()\n",
    "        in_text = seed_text\n",
    "        # generate a fixed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "            # truncate sequences to a fixed length\n",
    "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "            # predict probabilities for each word\n",
    "            yhat = model.predict_classes(encoded, verbose=0)\n",
    "            # map predicted word index to word\n",
    "            out_word = ''\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            # append to input\n",
    "            in_text += ' ' + out_word\n",
    "            result.append(out_word)\n",
    "        return ' '.join(result)\n",
    "\n",
    "    # load the model\n",
    "    model = load_model(model_file)\n",
    "\n",
    "    # load the tokenizer\n",
    "    tokenizer = load(open(tokenizer_pickle_file, 'rb'))\n",
    "\n",
    "    # select a seed text\n",
    "    seed_text = input_lyrics\n",
    "    print('Input text -----')\n",
    "    print(seed_text + '\\n')\n",
    "    \n",
    "    # generate new text\n",
    "    generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "    print('Predicted text -----')\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text -----\n",
      "take me with you i do declare i love you dearly through here and there what can i do to make you share what can i do to make you care the world is harsh i'm stuck in the dark i'll make my mark i've got my spark we'd be together\n",
      "\n",
      "Predicted text -----\n",
      "soon with the crowds and i'm going too fast and i'll think i say i know she's seems to the man like most of the same time don't make me company this to look gonna make me laugh as we're not friends nor have i wanna runaway now for the\n"
     ]
    }
   ],
   "source": [
    "lyrics = \"take me with you i do declare i love you dearly through here and there what can i do to make you share what can i do to make you care the world is harsh i'm stuck in the dark i'll make my mark i've got my spark we'd be together\"\n",
    "generate_song(lyrics, '/home/affine/Deep Learning/Ed-Sheeran-Lyrics-Generator-master/Models/bi_rnnglove2565010.0.h5', '/home/affine/Deep Learning/Ed-Sheeran-Lyrics-Generator-master/Models/bi_rnnglove2565010.0_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
